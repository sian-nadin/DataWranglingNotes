{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling: Gathering data\n",
    "Notes on methods for gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to look at **Rotten Tomatoes top 100 movies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Rotten Tomatoes bestofrt TSV file into a DataFrame\n",
    "df = pd.read_csv('bestofrt.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>critic_score</th>\n",
       "      <th>title</th>\n",
       "      <th>number_of_critic_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>The Wizard of Oz (1939)</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>Citizen Kane (1941)</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>The Third Man (1949)</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>Get Out (2017)</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>Mad Max: Fury Road (2015)</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking  critic_score                      title  number_of_critic_ratings\n",
       "0        1            99    The Wizard of Oz (1939)                       110\n",
       "1        2           100        Citizen Kane (1941)                        75\n",
       "2        3           100       The Third Man (1949)                        77\n",
       "3        4            99             Get Out (2017)                       282\n",
       "4        5            97  Mad Max: Fury Road (2015)                       370"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if the file was imported correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the movies on the list we can see that the critics scores and the audience scores don't line up. Some films, like ET, have quite a big difference in scores between critics and the audience. \n",
    "\n",
    "We can get the data on critics and audience scores using web scraping. We will use **Beautiful soup** to parse the HTML file on the top 100 movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing HTML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for programmatically downloading HTML file to your computer:\n",
    "\n",
    "The two main ways to work with HTML files are:\n",
    "\n",
    "1. Saving the HTML file to your computer (using the Requests library for example) library and reading that file into a BeautifulSoup constructor\n",
    "2. Reading the HTML response content directly into a BeautifulSoup constructor (again using the Requests library for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First method of working with HTML\n",
    "#This is just the code to download 1 file. We have 100 HTML files to access so we would have to put the code in a loop \n",
    "\n",
    "import requests\n",
    "url = \"https://www.rottentomatoes.com/m/t_the_extraterrestrial\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# #Save HTML to file\n",
    "# with open(\"et_the_extraterrestrial.html, mode='wb) as file:\n",
    "#      file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second method:\n",
    "# Work with HTML in memory\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Beautiful soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you need to do is **make the soup**. That means passing the path to yout HTML file into a file handle, then passing that file handle into the Beautiful Soup constructor like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rt_html/et_the_extraterrestrial.html') as file:\n",
    "    soup = BeautifulSoup(file, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use  methods in the Beautiful soup library to easily find and extract data from this HTML. One of the most popular methods is the **find** method. Let's find the title of our movie using this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>E.T. The Extra-TerrestrialÂ (1982) - Rotten Tomatoes</title>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We'll find that theres only one \" <title> tag in this whle HTML document and inside this tag is the title of the movie. \n",
    "soup.find('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the title of the webpage and not the movie title only. To get just the movie title we'll have to do some string slicing. To access the contents of these tags we can use **.contents** which returns a list of the tags children. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E.T. The Extra-Terrestrial\\xa0(1982) - Rotten Tomatoes']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('title').contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there's only one thing within this tag the list is one item long and we can therefore access it using the index 0. We can use this with string slicing to grab everything from the first charchter in our string to the 18th last character(The length of the string ' - Rotten Tomatoes'). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E.T. The Extra-Terrestrial\\xa0(1982)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('title').contents[0][:-len(' - Rotten Tomatoes')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jupyter Notebook below contains template code that:\n",
    "\n",
    "* Creates an empty list, df_list, to which dictionaries will be appended. This list of dictionaries will eventually be converted to a pandas DataFrame (this is the most efficient way of building a DataFrame row by row).\n",
    "* Loops through each movie's Rotten Tomatoes HTML file in the rt_html folder.\n",
    "* Opens each HTML file and passes it into a file handle called file.\n",
    "* Creates a DataFrame called df by converting df_list using the pd.DataFrame constructor.\n",
    "\n",
    "Your task is to extract the title, audience score, and number of audience ratings in each HTML file so each trio can be appended as a dictionary to df_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List of dictionaries to build file by file and later convert to a DataFrame\n",
    "df_list = []\n",
    "folder = 'rt_html'\n",
    "for movie_html in os.listdir(folder):\n",
    "    with open(os.path.join(folder, movie_html)) as file:\n",
    "        # Make the soup\n",
    "        soup = BeautifulSoup(file, \"html.parser\")\n",
    "        \n",
    "        #Find title. We don't wnat the '- Rotten Tomatoes' part of the title so only take the part before that\n",
    "        title = soup.find('title').contents[0][:-len(' - Rotten tomatoes')]\n",
    "        \n",
    "        #First find the div with class name audience-score meter then find the only span element within and grab the \n",
    "        # contents without the % sign\n",
    "        audience_score = soup.find('div', class_='audience-score meter').find('span').contents[0][:-1]\n",
    "        \n",
    "        #Find the div with number of ratings\n",
    "        num_audience_ratings = soup.find('div', class_ = 'audience-info hidden-xs superPageFontColor')\n",
    "        \n",
    "        #Find the second span tag within the div which contains number of reviews just want number of reviews and \n",
    "        # strip out whitespace. Will need to convert string to int so have to replace comma with empty\n",
    "        num_audience_ratings = num_audience_ratings.find_all('div')[1].contents[2].strip().replace(',', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roger Ebert review\n",
    "We are going to look at Rogert Eberts reviews for each of the movies listed in Rotten Tomatoes top 100 movies. The files for these reviews have been stored on a Udacity page. We will download them programatically using Pyhtons **Request** libraray.\n",
    "\n",
    "Python requests library has a method called **.get** which will send the request for us, return the contents of the file we requested, which we can then save to a file. \n",
    "\n",
    "Here's how it's done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "folder_name = 'ebert_review'\n",
    "if not os.path.exists(folder_name): #create folder if it doesn't exist already\n",
    "    os.makedirs(folder_name)\n",
    "    \n",
    "# Request code:\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_11-e.t.-the-extra-terrestrial/11-e.t.-the-extra-terrestrial.txt'\n",
    "response=requests.get(url)\n",
    "# We haven't actually saved the response to anything yet but let's take a look at what the response looks like\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response code 200 means everything went well with the request.\n",
    "\n",
    "All the text in our text file is in our computers working memory right now within this response variable. It's stored in the body of the response which we can access using **.content** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'E.T. The Extra-Terrestrial (1982)\\nhttp://www.rogerebert.com/reviews/great-movie-et-the-extra-terrestrial-1982\\nDear Raven and Emil:\\n\\nSunday we sat on the big green couch and watched \"E.T. The Extra-Terrestrial\" together with your mommy and daddy. It was the first time either of you had seen it, although you knew a little of what to expect because we took the \"E.T.\" ride together at the Universal tour. I had seen the movie lots of times since it came out in 1982, so I kept one eye on the screen and the other on the two of you. I wanted to see how a boy on his fourth birthday, and a girl who had just turned 7 a week ago, would respond to the movie.\\n\\nWell, it \"worked\" for both of you, as we say in Grandpa Roger\\'s business.\\n\\nRaven, you never took your eyes off the screen--not even when it looked like E.T. was dying and you had to scoot over next to me because you were afraid.\\n\\nEmil, you had to go sit on your dad\\'s knee a couple of times, but you never stopped watching, either. No trips to the bathroom or looking for lost toys: You were watching that movie with all of your attention.\\n\\nThe early scenes show a spaceship landing, and they suggest that a little creature has been left behind. The ship escapes quickly after men in pickup trucks come looking for it. Their headlights and flashlights make visible beams through the foggy night, and you remembered the same effect during the ride at Universal. And the keys hanging from their belts jangle on the soundtrack. It\\'s how a lost little extraterrestrial would experience it.\\n\\nThen there are shots of a suburban house, sort of like the one you live in, with a wide driveway and a big backyard. A little boy named Elliott (Henry Thomas) is in the yard when he thinks he sees or hears something. We already know that it\\'s E.T.\\n\\nThe camera watches Elliott moving around. And Raven, that\\'s when you asked me, \"Is this E.T.\\'s vision?\" And I said, yes, we were seeing everything now from E.T.\\'s point of view. And I thought you\\'d asked a very good question, because most kids your age wouldn\\'t have noticed that the camera had a point of view--that we were seeing everything from low to the ground, as a short little creature would view it, and experiencing what he (or she) would see after wandering out of the woods on a strange planet.\\n\\nWhile we were watching, I realized how right you were to ask that question. The whole movie is based on what moviemakers call \"point of view.\" Almost every single important shot is seen either as E.T. would see it, or as Elliott would see it. And things are understood as they would understand them. There aren\\'t any crucial moments where the camera pulls back and seems to be a grownup. We\\'re usually looking at things through a child\\'s eye--or an alien\\'s.\\n\\nWhen Elliott and E.T. see each other for the first time, they both jump back in fright and surprise, and let out yelps. We see each of them from the other\\'s point of view. When the camera stands back to show a whole scene, it avoids showing it through adult eyes. There\\'s a moment, for example, when Elliott\\'s mom (Dee Wallace Stone) is moving around doing some housework, and never realizes that E.T. is scurrying around the room just out of her line of sight. The camera stays back away from her. We don\\'t see her looking this way and that, because it\\'s not about which way she\\'s looking.\\n\\nLater, we do get one great shot that shows what she sees: She\\'s looking in Elliott\\'s closet at all of his stuffed toys lined up, and doesn\\'t realize one of the \"toys\" is actually E.T. We all laughed at that shot, but it was an exception; basically we looked out through little eyes, not big ones. (For example, in the scene where they take E.T. trick-or-treating with a sheet over his head, and we can see out like he can through the holes in the sheet.)\\n\\nLater, in the scenes that really worried you, Raven, the men in the trucks come back. They know E.T. is in Elliott\\'s house, and they\\'re scientists who want to examine the alien creature. But there isn\\'t a single moment when they use grownup talk and explain what they\\'re doing. We only hear small pieces of their dialogue, as Elliott might overhear it.\\n\\nBy then we know Elliott and E.T. are linked mentally, so Elliott can sense that E.T. is dying. Elliott cries out to the adults to leave E.T. alone, but the adults don\\'t take him seriously. A kid knows what that feels like. And then, when Elliott gets his big brother to drive the getaway car, and the brother says, \"I\\'ve never driven in forward before!\\'\\' you could identify with that. Kids are always watching their parents drive, and never getting to do it themselves.\\n\\nWe loved the scene where the bicycles fly. We suspected it was coming, because E.T. had taken Elliott on a private bike flight earlier, so we knew he could do it. I was thinking that the chase scene before the bikes fly was a little too long, as if Steven Spielberg (who made the film) was trying to build up too much unnecessary suspense. But when those bikes took off, what a terrific moment! I remember when I saw the movie at Cannes; even the audience there, people who had seen thousands of movies, let out a whoop at that moment.\\n\\nThen there\\'s the scene at the end. E.T. has phoned home, and the spaceship has come to get him. He\\'s in the woods with Elliott. The gangplank on the ship comes down, and in the doorway we can see another creature like E.T. standing with the light behind.\\n\\nEmil, you said, \"That\\'s E.T.\\'s mommy!\\'\\' And then you paused a second, and said, \"Now how did I know that?\\'\\'\\n\\nWe all laughed, because you made it sound funny, as you often do--you\\'re a natural comedian. But remembering it now, I asked myself--how did Emil know that? It could have been E.T.\\'s daddy, or sister, or the pilot of the ship. But I agree with you it probably was his mommy, because she sounded just like a mommy as she made the noise of calling E.T.\\n\\nAnd then I thought, the fact that you knew that was a sign of how well Steven Spielberg made his movie. At 4, you are a little young to understand \"point of view,\\'\\' but you are old enough to react to one. For the whole movie, you\\'d been seeing almost everything through the eyes of E.T. or Elliott. By the last moments, you were identifying with E.T. And who did he miss the most? Who did he want to see standing in the spaceship door for him? His mommy.\\n\\nOf course, maybe Steven Spielberg didn\\'t see it the same way, and thought E.T. only seemed like a kid and was really 500 years old. That doesn\\'t matter, because Spielberg left it open for all of us. That\\'s the sign of a great filmmaker: He only explains what he has to explain, and with a great movie the longer it runs, the less has to be explained. Some other filmmaker who wasn\\'t so good might have had subtitles saying, \"E.T.? Are you out there? It\\'s Mommy!\\'\\' But that would have been dumb.\\n\\nAnd it would have deprived you, Emil, of the joy of knowing it was E.T.\\'s mommy, and the delight of being able to tell the rest of us.\\n\\nWell, that\\'s it for this letter. We had a great weekend, kids. I was proud of how brave you both were during your first pony rides. And proud of what good movie critics you are, too.\\n\\nLove, Grandpa Roger'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Response is in in Bytes format. \n",
    "* Using this and some basic file IO we're going to save this file to our computer. \n",
    "* We'll open a file called '11-e.t.-the-extra-terrestrial.txt', i.e. everything after the last / in the url. In order to get everything after the last / we'll use Python's split function. \n",
    "* We need to open the contents of this file which we'll then write the contents of the response variable to. We have to open this is wb mode (write binary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(folder_name,\n",
    "                      url.split('/')[-1]), mode='wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's how you download 1 file programatically. Let's check the contents of our folder ebert_reviews to make sure it worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "Programmatically download all of the Rogert Ebert review text files to a folder called ebert_reviews using the Requests library. Use a for loop in conjunction with the provided ebert_review_urls list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory if it doesn't already exist\n",
    "folder_name = 'ebert_reviews'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebert_review_urls = ['https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9900_1-the-wizard-of-oz-1939-film/1-the-wizard-of-oz-1939-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9901_2-citizen-kane/2-citizen-kane.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9901_3-the-third-man/3-the-third-man.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9902_4-get-out-film/4-get-out-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9902_5-mad-max-fury-road/5-mad-max-fury-road.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9902_6-the-cabinet-of-dr.-caligari/6-the-cabinet-of-dr.-caligari.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9903_7-all-about-eve/7-all-about-eve.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9903_8-inside-out-2015-film/8-inside-out-2015-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9903_9-the-godfather/9-the-godfather.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_10-metropolis-1927-film/10-metropolis-1927-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_11-e.t.-the-extra-terrestrial/11-e.t.-the-extra-terrestrial.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_12-modern-times-film/12-modern-times-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_14-singin-in-the-rain/14-singin-in-the-rain.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9905_15-boyhood-film/15-boyhood-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9905_16-casablanca-film/16-casablanca-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9905_17-moonlight-2016-film/17-moonlight-2016-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9906_18-psycho-1960-film/18-psycho-1960-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9906_19-laura-1944-film/19-laura-1944-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9906_20-nosferatu/20-nosferatu.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9907_21-snow-white-and-the-seven-dwarfs-1937-film/21-snow-white-and-the-seven-dwarfs-1937-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9907_22-a-hard-day27s-night-film/22-a-hard-day27s-night-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9907_23-la-grande-illusion/23-la-grande-illusion.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9908_25-the-battle-of-algiers/25-the-battle-of-algiers.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9908_26-dunkirk-2017-film/26-dunkirk-2017-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9908_27-the-maltese-falcon-1941-film/27-the-maltese-falcon-1941-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9909_29-12-years-a-slave-film/29-12-years-a-slave-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9909_30-gravity-2013-film/30-gravity-2013-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9909_31-sunset-boulevard-film/31-sunset-boulevard-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990a_32-king-kong-1933-film/32-king-kong-1933-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990a_33-spotlight-film/33-spotlight-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990a_34-the-adventures-of-robin-hood/34-the-adventures-of-robin-hood.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990b_35-rashomon/35-rashomon.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990b_36-rear-window/36-rear-window.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990b_37-selma-film/37-selma-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990c_38-taxi-driver/38-taxi-driver.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990c_39-toy-story-3/39-toy-story-3.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990c_40-argo-2012-film/40-argo-2012-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_41-toy-story-2/41-toy-story-2.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_42-the-big-sick/42-the-big-sick.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_43-bride-of-frankenstein/43-bride-of-frankenstein.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_44-zootopia/44-zootopia.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990e_45-m-1931-film/45-m-1931-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990e_46-wonder-woman-2017-film/46-wonder-woman-2017-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990e_48-alien-film/48-alien-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990f_49-bicycle-thieves/49-bicycle-thieves.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990f_50-seven-samurai/50-seven-samurai.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990f_51-the-treasure-of-the-sierra-madre-film/51-the-treasure-of-the-sierra-madre-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9910_52-up-2009-film/52-up-2009-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9910_53-12-angry-men-1957-film/53-12-angry-men-1957-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9910_54-the-400-blows/54-the-400-blows.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9911_55-logan-film/55-logan-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9911_57-army-of-shadows/57-army-of-shadows.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9912_58-arrival-film/58-arrival-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9912_59-baby-driver/59-baby-driver.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_60-a-streetcar-named-desire-1951-film/60-a-streetcar-named-desire-1951-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_61-the-night-of-the-hunter-film/61-the-night-of-the-hunter-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_62-star-wars-the-force-awakens/62-star-wars-the-force-awakens.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_63-manchester-by-the-sea-film/63-manchester-by-the-sea-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9914_64-dr.-strangelove/64-dr.-strangelove.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9914_66-vertigo-film/66-vertigo-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9914_67-the-dark-knight-film/67-the-dark-knight-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9915_68-touch-of-evil/68-touch-of-evil.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9915_69-the-babadook/69-the-babadook.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9915_72-rosemary27s-baby-film/72-rosemary27s-baby-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9916_73-finding-nemo/73-finding-nemo.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9916_74-brooklyn-film/74-brooklyn-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9917_75-the-wrestler-2008-film/75-the-wrestler-2008-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9917_77-l.a.-confidential-film/77-l.a.-confidential-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9918_78-gone-with-the-wind-film/78-gone-with-the-wind-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9918_79-the-good-the-bad-and-the-ugly/79-the-good-the-bad-and-the-ugly.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9918_80-skyfall/80-skyfall.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_82-tokyo-story/82-tokyo-story.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_83-hell-or-high-water-film/83-hell-or-high-water-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_84-pinocchio-1940-film/84-pinocchio-1940-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_85-the-jungle-book-2016-film/85-the-jungle-book-2016-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991a_86-la-la-land-film/86-la-la-land-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991b_87-star-trek-film/87-star-trek-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991b_89-apocalypse-now/89-apocalypse-now.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991c_90-on-the-waterfront/90-on-the-waterfront.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991c_91-the-wages-of-fear/91-the-wages-of-fear.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991c_92-the-last-picture-show/92-the-last-picture-show.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991d_93-harry-potter-and-the-deathly-hallows-part-2/93-harry-potter-and-the-deathly-hallows-part-2.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991d_94-the-grapes-of-wrath-film/94-the-grapes-of-wrath-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991d_96-man-on-wire/96-man-on-wire.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_97-jaws-film/97-jaws-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_98-toy-story/98-toy-story.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_99-the-godfather-part-ii/99-the-godfather-part-ii.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_100-battleship-potemkin/100-battleship-potemkin.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our text is stored in the body of the response which we can get using .content\n",
    "#Text stored in bytes format so open in mode='wb' \n",
    "for url in ebert_review_urls:\n",
    "#use GET to obtain data from URL\n",
    "    response = requests.get(url)\n",
    "    with open(os.path.join(folder_name,\n",
    "#for file name get everything after the last slash in the url\n",
    "#use split fxn to get last item in the list returned\n",
    "                      url.split('/')[-1]), mode='wb') as file:\n",
    "#write to file handle we've opened\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "We'll need to loop to iterate through all of the files in this folder to open and read each, then extract the bits of text that we need as separate pieces of data:\n",
    "\n",
    "* the first line a.k.a. the movie title (to merge to the master dataset with)\n",
    "* the second line a.k.a. the review URL (not necessary for the word cloud but nice to have)\n",
    "* everything from the third line onwards a.k.a. the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dictionaries to build file by file and later convert to a DataFrame\n",
    "df_list = []\n",
    "for ebert_review in glob.glob('ebert_reviews/*.txt'):\n",
    "    with open(ebert_review, encoding='utf-8') as file:\n",
    "        title = file.readline()[:-1]\n",
    "        review_url = file.readline()[:-1]\n",
    "        review_text = file.read()\n",
    "\n",
    "        # Append to list of dictionaries\n",
    "        df_list.append({'title': title,\n",
    "                        'review_url': review_url,\n",
    "                        'review_text': review_text})\n",
    "df = pd.DataFrame(df_list, columns = ['title', 'review_url', 'review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source: APIs (Application Programming Interfaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MediaWiki API\n",
    "Allows you to extract data from Wikipedia.The most up to date and human readable library for MediaWiki in Python is called wptools.\n",
    "\n",
    "To get a page object, the usage is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wptools\n",
    "page = wptools.page('Mahatma_Gandhi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...where 'Mahatma_Gandhi' is the last bit of the Wikipedia URL for that page (https://en.wikipedia.org/wiki/Mahatma_Gandhi). This page object has methods that can get us various pieces of data about that Wikipedia page, including all of the images on the page. To get all of the data:\n",
    "\n",
    "Simply calling get() on a page will automagically fetch extracts, images, infobox data, wikidata, and other metadata via the MediaWiki, Wikidata, and RESTBase APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = wptools.page('Mahatma_Gandhi').get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if you already have a page object assigned to page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "page now has a list of attributes, which can be accessed using dot notation through .data \n",
    "\n",
    "page.data['image'], for example, would return a list of data for six images on this specific Wikipedia page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "Get the page object for the E.T. The Extra-Terrestial Wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "page = wptools.page('E.T._the_Extra-Terrestrial').get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the image attribute will return the images for this page\n",
    "page.data['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Files in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "Let's inspect the wptools page object for the E.T. The Extra-Terrestial Wikipedia page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = wptools.page('E.T._the_Extra-Terrestrial').get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the first image in the images attribute, which is a JSON array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.data['image'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the director key of the infobox attribute, which is a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.data['infobox']['director']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two main ways to work with HTML files are:\n",
    "\n",
    "* Saving the HTML file to your computer (using the Requests library for example) library and reading that file into a BeautifulSoup constructor\n",
    "* Reading the HTML response content directly into a BeautifulSoup constructor (again using the Requests library for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
